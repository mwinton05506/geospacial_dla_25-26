{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee7472",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, mixed_precision\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mDenseCL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseCL\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, mixed_precision\n",
    "from utils.DenseCL import DenseCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1447a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA T550 Laptop GPU, compute capability 7.5\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] replicas: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 10:28:25.327322: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.377041: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.377080: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.377814: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.382970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.383036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.383050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.772695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.772760: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.772771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-02-07 10:28:25.772809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 10:28:25.772836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2252 MB memory:  -> device: 0, name: NVIDIA T550 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\" if gpus else \"float32\")\n",
    "\n",
    "if len(gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "elif len(gpus) == 1:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/GPU:0\")\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/CPU:0\")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print(\"GPUs:\", gpus, \"replicas:\", strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10e1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cpu_compiler', '/usr/lib/llvm-17/bin/clang'),\n",
       "             ('cuda_compute_capabilities',\n",
       "              ['sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']),\n",
       "             ('cuda_version', '12.2'),\n",
       "             ('cudnn_version', '8'),\n",
       "             ('is_cuda_build', True),\n",
       "             ('is_rocm_build', False),\n",
       "             ('is_tensorrt_build', True)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918f562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 10:28:45.973182: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2026-02-07 10:28:46.171830: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:30] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_IMAGE'\n",
      "\n",
      "2026-02-07 10:28:46.171880: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:30] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2026-02-07 10:28:46.171893: W tensorflow/core/framework/op_kernel.cc:1827] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__Minimum_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Minimum] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- STEP 3: COSINE LEARNING RATE SCHEDULE ---\u001b[39;00m\n\u001b[32m     13\u001b[39m lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n\u001b[32m     14\u001b[39m     initial_learning_rate=\u001b[32m0.0\u001b[39m,  \u001b[38;5;66;03m# Start at 0 for warmup\u001b[39;00m\n\u001b[32m     15\u001b[39m     decay_steps=STEPS_PER_EPOCH * EPOCHS,\n\u001b[32m     16\u001b[39m     warmup_target=\u001b[32m1e-3\u001b[39m,  \u001b[38;5;66;03m# Target LR from your notebook\u001b[39;00m\n\u001b[32m     17\u001b[39m     warmup_steps=STEPS_PER_EPOCH * \u001b[32m2\u001b[39m,  \u001b[38;5;66;03m# 2 epochs of warmup\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m optimizer = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m model = DenseCL(backbone)\n\u001b[32m     23\u001b[39m model.compile(optimizer=optimizer, run_eagerly=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/keras/src/optimizers/adam.py:122\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     94\u001b[39m     learning_rate=\u001b[32m0.001\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m     **kwargs\n\u001b[32m    109\u001b[39m ):\n\u001b[32m    110\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    111\u001b[39m         name=name,\n\u001b[32m    112\u001b[39m         weight_decay=weight_decay,\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m         **kwargs\n\u001b[32m    121\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28mself\u001b[39m._learning_rate = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_learning_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m.beta_1 = beta_1\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.beta_2 = beta_2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:1282\u001b[39m, in \u001b[36mOptimizer._build_learning_rate\u001b[39m\u001b[34m(self, learning_rate)\u001b[39m\n\u001b[32m   1280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_learning_rate\u001b[39m(\u001b[38;5;28mself\u001b[39m, learning_rate):\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mesh:\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_build_learning_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m# For DTensor\u001b[39;00m\n\u001b[32m   1285\u001b[39m     variable_creation = tf.experimental.dtensor.DVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:385\u001b[39m, in \u001b[36m_BaseOptimizer._build_learning_rate\u001b[39m\u001b[34m(self, learning_rate)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.init_scope():\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    381\u001b[39m         learning_rate, learning_rate_schedule.LearningRateSchedule\n\u001b[32m    382\u001b[39m     ):\n\u001b[32m    383\u001b[39m         \u001b[38;5;66;03m# Create a variable to hold the current learning rate.\u001b[39;00m\n\u001b[32m    384\u001b[39m         current_learning_rate = tf.convert_to_tensor(\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m             \u001b[43mlearning_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m         )\n\u001b[32m    387\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_learning_rate = tf.Variable(\n\u001b[32m    388\u001b[39m             current_learning_rate,\n\u001b[32m    389\u001b[39m             name=\u001b[33m\"\u001b[39m\u001b[33mcurrent_learning_rate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    390\u001b[39m             dtype=current_learning_rate.dtype,\n\u001b[32m    391\u001b[39m             trainable=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    392\u001b[39m         )\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m learning_rate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/keras/src/optimizers/schedules/learning_rate_schedule.py:739\u001b[39m, in \u001b[36mCosineDecay.__call__\u001b[39m\u001b[34m(self, step)\u001b[39m\n\u001b[32m    736\u001b[39m warmup_target = tf.cast(\u001b[38;5;28mself\u001b[39m.warmup_target, dtype)\n\u001b[32m    737\u001b[39m warmup_steps = tf.cast(\u001b[38;5;28mself\u001b[39m.warmup_steps, dtype)\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m global_step_recomp = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mglobal_step_recomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_steps\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tf.cond(\n\u001b[32m    744\u001b[39m     global_step_recomp < warmup_steps,\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m._warmup_function(\n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m     ),\n\u001b[32m    757\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py:6605\u001b[39m, in \u001b[36mminimum\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   6603\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6604\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m6605\u001b[39m   \u001b[43m_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6606\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   6607\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DLA/geospacial_dla_25-26/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5881\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5882\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5883\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInternalError\u001b[39m: {{function_node __wrapped__Minimum_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Minimum] name: "
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync  # Scale batch size with GPUs\n",
    "EPOCHS = 25\n",
    "STEPS_PER_EPOCH = 8166 // BATCH_SIZE # There are 8166 images in the training set\n",
    "\n",
    "with strategy.scope():\n",
    "    # Model definition must happen inside strategy scope\n",
    "    backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights=None, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    # --- STEP 3: COSINE LEARNING RATE SCHEDULE ---\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=0.0,  # Start at 0 for warmup\n",
    "        decay_steps=STEPS_PER_EPOCH * EPOCHS,\n",
    "        warmup_target=1e-3,  # Target LR from your notebook\n",
    "        warmup_steps=STEPS_PER_EPOCH * 2,  # 2 epochs of warmup\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model = DenseCL(backbone)\n",
    "    model.compile(optimizer=optimizer, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480c1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def make_two_views(image):\n",
    "    # Keep input pipeline numerics stable; mixed precision policy handles compute casts.\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return (data_augment(image, training=True), data_augment(image, training=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords(source_dir, output_file):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                image_paths.append(os.path.join(root, f))\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        for path in image_paths:\n",
    "            img_raw = open(path, \"rb\").read()\n",
    "            example = tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        \"image\": tf.train.Feature(\n",
    "                            bytes_list=tf.train.BytesList(value=[img_raw])\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "# Convert your data\n",
    "create_tfrecords(\"E:\\\\figures_no_labeled\", \"figures_data.tfrecords\")\n",
    "\n",
    "\n",
    "# --- UPDATED LOADER FOR JUPYTER ---\n",
    "def decode_fn(record_bytes):\n",
    "    feats = tf.io.parse_single_example(\n",
    "        record_bytes, {\"image\": tf.io.FixedLenFeature([], tf.string)}\n",
    "    )\n",
    "    image = tf.io.decode_jpeg(feats[\"image\"], channels=3)\n",
    "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    return image\n",
    "\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(\"figures_data.tfrecords\")\n",
    "train_ds = train_ds.shuffle(1000).map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).map(make_two_views).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9e757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8166 files.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:\\\\Figures\",\n",
    "    label_mode=None,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Optimization: Cache in memory (if RAM allows) and use AUTOTUNE\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.map(make_two_views, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84dc3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.20.0\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Devices:\", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=\"logs/densecl_test\")],\n",
    ")\n",
    "\n",
    "model.backbone.save(\"models/densecl_resnet50_optimized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.11
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
